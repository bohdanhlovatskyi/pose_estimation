{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa686a70-2c4a-45c1-95c2-6a051089700e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Library/Frameworks/Python.framework/Versions/3.8/bin/python3.8'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c667c9b-b0de-48ba-899e-11c197ca6f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import statistics\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "from pytorch3d.transforms import matrix_to_quaternion\n",
    "\n",
    "import poselib\n",
    "\n",
    "from solver import Up2P\n",
    "from SolverPipeline import P3PBindingWrapperPipeline\n",
    "from SolverPipeline import SolverPipeline as SP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6977b51-686f-4339-be7e-1b5d98141fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "VSP = \"dataset/StMarysChurch_matches\"\n",
    "seq = [3, 5, 13]\n",
    "SHOW_SINGLE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86247417-9a9f-4d8d-bc28-c9ea829a5b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    ransac_thresh = 13.\n",
    "    max_side_length = 320\n",
    "    max_ransac_iters = 10000\n",
    "    \n",
    "conf = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64b98253-1a4f-4d7e-83da-ef91061380ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "p3pwrapper = P3PBindingWrapperPipeline(\n",
    "    ransac_conf = {\n",
    "       # 'max_reproj_error': args.ransac_thresh\n",
    "       'min_iterations': min(100, conf.max_ransac_iters),\n",
    "       'max_iterations': conf.max_ransac_iters,\n",
    "       'progressive_sampling': True,\n",
    "       'max_prosac_iterations': conf.max_ransac_iters\n",
    "    },\n",
    "    \n",
    "    bundle_adj_conf = {\n",
    "        'loss_scale' : 1.0,\n",
    "    }                                              \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b65ffd7-72cc-4f87-b7f3-02f4cbd5da7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "camera = {'model': 'SIMPLE_RADIAL', 'width': 320, 'height': 180, 'params': [277.4716064453125, 160.0, 90.0, 0.0]}\n",
    "pts2D = [\n",
    "    np.array([192.12533569,  19.14378548]),\n",
    "    np.array([91.60398102, 26.73556519]),\n",
    "    np.array([180.32232666,  33.99654388]),\n",
    "    np.array([192.33743286,  37.74715424]),\n",
    "    np.array([188.43441772,  41.1788559 ])\n",
    "]\n",
    "\n",
    "pts3D = [\n",
    "    np.array([ 11.86180782, -14.56327057,  -0.92378181]),\n",
    "    np.array([ 6.79015875, -9.56949902, -1.78533459]),\n",
    "    np.array([11.95058823, -0.89410073, -0.36948705]), \n",
    "    np.array([ 12.17275715, -13.31939125,  -0.34633577]),\n",
    "    np.array([ 7.56372643, -2.60536647, -2.24980545])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9fa0aadf-c029-4928-8038-f931b2198c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UP2PSolverPipeline(SP):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.solver = Up2P()\n",
    "    \n",
    "    def __call__(self, pts2D, pts3D, camera_dict):\n",
    "        \n",
    "        w, h = camera_dict[\"width\"], camera_dict[\"height\"]\n",
    "        params = camera_dict[\"params\"]\n",
    "        f, cx, cy, _ = params\n",
    "        \n",
    "        pts2D = np.concatenate([pts2D, np.ones(pts2D.shape[0])[:, np.newaxis]], axis=1)\n",
    "        pts2D[:, 0] -= cx\n",
    "        pts2D[:, 1] -= cy\n",
    "        pts2D[:2] /= f\n",
    "        pts2D /= np.linalg.norm(pts2D)\n",
    "        \n",
    "        solution, sol_err = None, float(\"+inf\")\n",
    "        \n",
    "        for i in range(2, len(pts2D)):\n",
    "            try:\n",
    "                solv_res = self.solver(pts2D[i - 2 : i], pts3D[i - 2 : i])\n",
    "                best_sol, err = None, float(\"+inf\")\n",
    "\n",
    "                for sol in solv_res:\n",
    "                    R, t = sol\n",
    "                    R, t = R.detach().cpu().numpy(), t.detach().cpu().numpy()\n",
    "                    translated = R.T @ (pts3D[i] - t)\n",
    "                    translated[:2] /= translated[2]\n",
    "                    translated[:2] *= f\n",
    "                    translated[0] += cx\n",
    "                    translated[1] += cy\n",
    "                    if np.linalg.norm(translated - pts2D[i]) < err:\n",
    "                        err = np.linalg.norm(translated - pts2D[i])\n",
    "                        best_sol = sol\n",
    "\n",
    "                if err < sol_err:\n",
    "                    sol_err = err\n",
    "                    solution = best_sol    \n",
    "            except Exception as ex:\n",
    "                # print(ex)\n",
    "                continue\n",
    "        \n",
    "        pose = poselib.CameraPose()\n",
    "        pose.q = matrix_to_quaternion(solution[0])\n",
    "        pose.t = solution[1]\n",
    "        \n",
    "        return pose\n",
    "        \n",
    "solv_pipe = UP2PSolverPipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a9a4a451-7a08-4cb5-972c-0f4ef2d763d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([q: 0.876781        0 0.480889        0, t:  18.1798 -30.5427 -9.15747],\n",
       " poselib.CameraPose)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = solv_pipe(\n",
    "    np.array(pts2D),\n",
    "    np.array(pts3D),\n",
    "    camera\n",
    ")\n",
    "res, type(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f5247103-2b96-4c94-bfea-7064c25d7ad4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[q:  0.770395 -0.620412  0.145098 -0.022967, t:   12.4091   4.84072 -0.453523]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pose = p3pwrapper(\n",
    "    np.array(pts2D),\n",
    "    np.array(pts3D),\n",
    "    camera\n",
    ")\n",
    "pose.t = - pose.R.T @ pose.t\n",
    "pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "78988031-6139-4f07-8ae7-a44b4b1f47ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(executor: SP, path: str, conf, camera_dict, gts):\n",
    "    data = np.load(path)\n",
    "    pts2D = list(data[:, :2])\n",
    "    pts3D = list(data[:, 2:])\n",
    "    pp = \"/\".join(path.split(\"/\")[-2:])\n",
    "    pp = pp.replace(\"_matches\", \"\")\n",
    "    pp = pp.replace(\".npy\", \".png\")\n",
    "    camera_dict = camera_dict[pp]\n",
    "    gt = gts[pp]\n",
    "    c, r = gt[:3], gt[3:]\n",
    "\n",
    "    pose = executor(np.array(pts2D), np.array(pts3D), camera_dict)\n",
    "\n",
    "    pose.t = - pose.R.T @ pose.t          \n",
    "\n",
    "    gt_pose = poselib.CameraPose()\n",
    "    gt_pose.q = r / np.linalg.norm(r)\n",
    "\n",
    "    rot_error = np.arccos((np.trace(np.matmul(gt_pose.R.transpose(), pose.R)) - 1.0) / 2.0) * 180.0 / np.pi\n",
    "\n",
    "    if SHOW_SINGLE:\n",
    "        print(np.trace(np.matmul(gt_pose.R.transpose(), pose.R)))\n",
    "        print(\" Position error: \" + str(np.linalg.norm(c - pose.t)) + \" orientation error: \" + str(rot_error))\n",
    "    if np.isnan(rot_error):\n",
    "        return 1000000.0, 180.0\n",
    "    else:\n",
    "        return np.linalg.norm(c - pose.t), rot_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "23ecb0a8-f54e-41c2-9972-e3eb0bb2d259",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_camera_dict(path: str, args):\n",
    "    with open(path) as file:\n",
    "        data = file.readlines()\n",
    "\n",
    "    camera_dict = {}\n",
    "    for _, line in enumerate(data):\n",
    "        # image width, image height, focal length, x of pp, y of pp, radial distortion factor \n",
    "        path, cam_type, w, h, f, x, y, rd = line.split()\n",
    "        scaling_factor = 320 / max(np.float32(w), np.float32(h))\n",
    "  \n",
    "        # camera = {'model': 'SIMPLE_PINHOLE', 'width': 1200, 'height': 800, 'params': [960, 600, 400]}\n",
    "        camera_dict[path] = {\n",
    "          'model': cam_type,\n",
    "          'width': int(np.float32(w) * scaling_factor),\n",
    "          'height': int(np.float32(h) * scaling_factor),\n",
    "          'params': list(map(float, [np.float32(f) * scaling_factor,\n",
    "                                 np.float32(x) * scaling_factor,\n",
    "                                 np.float32(y) * scaling_factor,\n",
    "                                 np.float32(rd)])),\n",
    "        }\n",
    "  \n",
    "    return camera_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "32718520-eed5-4863-b903-72f540a70216",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_gts(path: str):\n",
    "    # ImageFile, Camera Position [X Y Z W P Q R]\n",
    "\n",
    "    with open(path) as file:\n",
    "        data = file.readlines()\n",
    "\n",
    "    gts = {}\n",
    "    for _, line in enumerate(data):\n",
    "        try:\n",
    "          # seq13/frame00158.png 25.317314 -0.228082 54.493720 0.374564 0.002123 0.915022 -0.149782\n",
    "          path, x, y, z, w, p, q, r = line.split()\n",
    "          rest = [x, y, z, w, p, q, r]\n",
    "          rest = list(map(float, rest))\n",
    "        except Exception as ex:\n",
    "          # print(ex)\n",
    "          continue\n",
    "        gts[path] = rest\n",
    "\n",
    "    return gts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a7ccff08-7bad-4ea0-9545-0e084f2f8ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_dict = prepare_camera_dict(\n",
    "    \"dataset/StMarysChurch_matches/st_marys_church_list_queries_with_intrinsics_simple_radial_sorted.txt\",\n",
    "    conf\n",
    ")\n",
    "\n",
    "gt_dict = prepare_gts(\n",
    "    \"dataset/StMarysChurch_matches/dataset_test.txt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ef86a24f-de8f-4ee5-a488-81adb5010163",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [00:00<00:00, 225.70it/s]\n",
      "100%|██████████| 83/83 [00:00<00:00, 188.78it/s]\n",
      "100%|██████████| 351/351 [00:02<00:00, 129.42it/s]\n"
     ]
    }
   ],
   "source": [
    "orientation_errors, pose_errors = [], []\n",
    "for s in seq:\n",
    "    p = f\"{VSP}/seq{s}\"\n",
    "    for f in tqdm(os.listdir(p)):\n",
    "        if f.split(\".\")[1] != \"npy\":\n",
    "            continue\n",
    "        pe, oe = process_file(p3pwrapper, f\"{p}/{f}\", conf, camera_dict, gt_dict)\n",
    "        pose_errors.append(pe)\n",
    "        orientation_errors.append(oe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2b84dc38-935e-4c45-aeda-20787d5df81b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Couldn't localize 0 out of 530 images\n",
      " Median position error: 0.086, median orientation errors: 0.29\n",
      " Percentage of poses within the median: 41.132075471698116 % \n"
     ]
    }
   ],
   "source": [
    "pos_errors = pose_errors\n",
    "orient_errors = orientation_errors\n",
    "print(\" Couldn't localize \" + str(orientation_errors.count(180.0)) + \" out of \" + str(len(orientation_errors)) + \" images\") \n",
    "print(\" Median position error: \" +  str(round(statistics.median(pos_errors),3)) + \", median orientation errors: \" + str(round(statistics.median(orient_errors),2)))\n",
    "\n",
    "med_pos = statistics.median(pos_errors)\n",
    "med_orient = statistics.median(orient_errors)\n",
    "counter = 0\n",
    "for i in range(0, len(pose_errors)):\n",
    "    if pose_errors[i] <= med_pos and orientation_errors[i] <= med_orient:\n",
    "        counter += 1\n",
    "print(\" Percentage of poses within the median: \" + str(100.0 * float(counter) / float(len(pose_errors))) + \" % \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3283ef61-c62e-4b85-8437-558c5861c2f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [00:37<00:00,  2.64it/s]\n",
      "100%|██████████| 83/83 [00:49<00:00,  1.66it/s]\n",
      "100%|██████████| 351/351 [01:52<00:00,  3.13it/s]\n"
     ]
    }
   ],
   "source": [
    "orientation_errors, pose_errors = [], []\n",
    "for s in seq:\n",
    "    p = f\"{VSP}/seq{s}\"\n",
    "    for f in tqdm(os.listdir(p)):\n",
    "        if f.split(\".\")[1] != \"npy\":\n",
    "            continue\n",
    "        pe, oe = process_file(solv_pipe, f\"{p}/{f}\", conf, camera_dict, gt_dict)\n",
    "        pose_errors.append(pe)\n",
    "        orientation_errors.append(oe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c27f9d12-dab9-42d3-9807-0333df328093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Couldn't localize 0 out of 530 images\n",
      " Median position error: 30.337, median orientation errors: 103.41\n",
      " Percentage of poses within the median: 25.09433962264151 % \n"
     ]
    }
   ],
   "source": [
    "pos_errors = pose_errors\n",
    "orient_errors = orientation_errors\n",
    "print(\" Couldn't localize \" + str(orientation_errors.count(180.0)) + \" out of \" + str(len(orientation_errors)) + \" images\") \n",
    "print(\" Median position error: \" +  str(round(statistics.median(pos_errors),3)) + \", median orientation errors: \" + str(round(statistics.median(orient_errors),2)))\n",
    "\n",
    "med_pos = statistics.median(pos_errors)\n",
    "med_orient = statistics.median(orient_errors)\n",
    "counter = 0\n",
    "for i in range(0, len(pose_errors)):\n",
    "    if pose_errors[i] <= med_pos and orientation_errors[i] <= med_orient:\n",
    "        counter += 1\n",
    "print(\" Percentage of poses within the median: \" + str(100.0 * float(counter) / float(len(pose_errors))) + \" % \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7d5e4c-3a7c-4b24-830f-be7a9380148b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
