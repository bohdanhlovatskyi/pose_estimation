{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa686a70-2c4a-45c1-95c2-6a051089700e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.executable\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c667c9b-b0de-48ba-899e-11c197ca6f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import statistics\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(rc={'figure.figsize':(16,10)})\n",
    "\n",
    "import torch\n",
    "\n",
    "from tqdm import tqdm\n",
    "from scipy.spatial.transform import Rotation\n",
    "from pytorch3d.transforms import matrix_to_quaternion\n",
    "\n",
    "import poselib\n",
    "\n",
    "from solver import Up2P, Solver\n",
    "from SolverPipeline import P3PBindingWrapperPipeline\n",
    "from SolverPipeline import SolverPipeline as SP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6977b51-686f-4339-be7e-1b5d98141fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "VSP = \"dataset/StMarysChurch_matches\"\n",
    "seq = [3, 5, 13]\n",
    "SHOW_SINGLE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86247417-9a9f-4d8d-bc28-c9ea829a5b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    ransac_thresh = 13.\n",
    "    max_side_length = 320\n",
    "    max_ransac_iters = 10000\n",
    "    \n",
    "conf = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64b98253-1a4f-4d7e-83da-ef91061380ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "p3pwrapper = P3PBindingWrapperPipeline(\n",
    "    ransac_conf = {\n",
    "       # 'max_reproj_error': args.ransac_thresh\n",
    "       'min_iterations': min(100, conf.max_ransac_iters),\n",
    "       'max_iterations': conf.max_ransac_iters,\n",
    "       'progressive_sampling': True,\n",
    "       'max_prosac_iterations': conf.max_ransac_iters\n",
    "    },\n",
    "    \n",
    "    bundle_adj_conf = {\n",
    "        'loss_scale' : 1.0,\n",
    "    }                                              \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b65ffd7-72cc-4f87-b7f3-02f4cbd5da7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "camera = {'model': 'SIMPLE_RADIAL', 'width': 320, 'height': 180, 'params': [277.4716064453125, 160.0, 90.0, 0.0]}\n",
    "pts2D = [\n",
    "    np.array([192.12533569,  19.14378548]),\n",
    "    np.array([91.60398102, 26.73556519]),\n",
    "    np.array([180.32232666,  33.99654388]),\n",
    "    np.array([192.33743286,  37.74715424]),\n",
    "    np.array([188.43441772,  41.1788559 ])\n",
    "]\n",
    "\n",
    "pts3D = [\n",
    "    np.array([ 11.86180782, -14.56327057,  -0.92378181]),\n",
    "    np.array([ 6.79015875, -9.56949902, -1.78533459]),\n",
    "    np.array([11.95058823, -0.89410073, -0.36948705]), \n",
    "    np.array([ 12.17275715, -13.31939125,  -0.34633577]),\n",
    "    np.array([ 7.56372643, -2.60536647, -2.24980545])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab102379-7cf2-48d3-91fb-a57453e99ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampler:\n",
    "    \n",
    "    def __call__(self, pts: np.array, sample_size: int):\n",
    "        n = len(pts)\n",
    "        assert n > sample_size\n",
    "        \n",
    "        idcs = np.random.choice(n, sample_size)\n",
    "        \n",
    "        return pts[idcs], idcs\n",
    "    \n",
    "sampler = Sampler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07a587ea-16bb-4f51-afd9-4c95d977c44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DisplacementRefinerSolver(Solver):\n",
    "    \n",
    "    def __init__(self, min_sample_size: int = 100, models_to_evaluate: int = 3, verbose: bool = False):\n",
    "        self.min_sample_size = min_sample_size\n",
    "        self.models_to_evaluate = models_to_evaluate\n",
    "        self.internal_solver = Up2P()\n",
    "        self.verbose = verbose\n",
    "    \n",
    "    def get_sample_size(self) -> int:\n",
    "        return self.min_sample_size\n",
    "    \n",
    "    def __call__(self, x, X, camera_dict):\n",
    "        # assert x.shape == (self.min_sample_size, 3)\n",
    "        # assert X.shape == (self.min_sample_size, 3)\n",
    "        assert x.shape[0] == X.shape[0]\n",
    "        \n",
    "        w, h = camera_dict[\"width\"], camera_dict[\"height\"]\n",
    "        params = camera_dict[\"params\"]\n",
    "        f, cx, cy, _ = params\n",
    "        \n",
    "        x = np.concatenate([x, np.ones(x.shape[0])[:, np.newaxis]], axis=1)\n",
    "        x[:, 0] -= cx\n",
    "        x[:, 1] -= cy\n",
    "        x[:2] /= f\n",
    "        x /= np.linalg.norm(x)\n",
    "        \n",
    "        idcs = np.random.choice(len(X), self.internal_solver.get_sample_size() + 1)\n",
    "        xx, XX = x[idcs[:idcs.shape[0] - 1]], X[idcs[:idcs.shape[0] - 1]]\n",
    "            \n",
    "        solv_res = self.internal_solver(xx, XX)\n",
    "            \n",
    "        err, Rf, tf = None, None, None\n",
    "        for sol in solv_res:\n",
    "            R, t = sol\n",
    "            R, t = R.detach().cpu().numpy(), t.detach().cpu().numpy()\n",
    "         \n",
    "            gts, projs = [], []\n",
    "            for (xx, XX) in zip(x, X):\n",
    "                proj = R.T @ (XX - t)\n",
    "                proj[:2] /= proj[2]\n",
    "                proj[:2] *= f\n",
    "                proj[0] += cx\n",
    "                proj[1] += cy\n",
    "                gts.append(xx)\n",
    "                projs.append(proj)\n",
    "                    \n",
    "            _, angles = self._get_rot_angles(np.stack(gts)[:, 2], np.stack(projs)[:, :2])\n",
    "                \n",
    "            deg_angles = [angle.as_euler(\"XYZ\", degrees=True)[2] for angle in angles]\n",
    "\n",
    "            if self.verbose:\n",
    "                plt.hist(deg_angles, density=True, color='black', bins=np.arange(-180, 180, 5))\n",
    "                plt.xticks(range(-180, 180, 5))\n",
    "                plt.show()\n",
    "                \n",
    "            counts = np.bincount([angle + 180.0 for angle in deg_angles])\n",
    "            prerotate_with = angles[np.argmax(counts)].as_matrix()\n",
    "                \n",
    "            Xs = np.array([prerotate_with.T @ XX for XX in X.copy()])\n",
    "            iidcs = np.random.choice(len(X), self.internal_solver.get_sample_size() + 1)\n",
    "            internal_x, internal_X = x[iidcs], Xs[iidcs]\n",
    "                \n",
    "            inner_solv_res = self.internal_solver(\n",
    "                internal_x[:internal_x.shape[0] - 1],\n",
    "                internal_X[:internal_X.shape[0] - 1],\n",
    "            )\n",
    "                \n",
    "            ierr, IR, It = None, None, None\n",
    "            for iR, it in inner_solv_res:\n",
    "                rp = R.T @ (internal_X[internal_X.shape[0] - 1] - t)\n",
    "                rp[:2] /= rp[2]\n",
    "                rp[:2] *= f\n",
    "                rp[0] += cx\n",
    "                rp[1] += cy\n",
    "                    \n",
    "                cerr = np.linalg.norm(internal_x[internal_x.shape[0] - 1] - rp)\n",
    "                if ierr is None or cerr < ierr:\n",
    "                    ierr = cerr\n",
    "                    IR, It = iR, it\n",
    "                   \n",
    "            R = prerotate_with @ IR.detach().cpu().numpy()\n",
    "            \n",
    "            rp = R.T @ (XX[idcs.shape[0] - 1] - t)\n",
    "            rp[:2] /= rp[2]\n",
    "            rp[:2] *= f\n",
    "            rp[0] += cx\n",
    "            rp[1] += cy\n",
    "                        \n",
    "            cerr = np.linalg.norm(xx[idcs.shape[0] - 1] - rp)\n",
    "            if err is None or cerr < err:\n",
    "                err = cerr\n",
    "                Rf, tf = R, t\n",
    "                \n",
    "        pose = poselib.CameraPose()\n",
    "        try:\n",
    "            pose.q = matrix_to_quaternion(torch.tensor(Rf))\n",
    "            pose.t = tf\n",
    "\n",
    "            return pose\n",
    "        except:\n",
    "            return None\n",
    "                \n",
    "                    \n",
    "    def _get_rot_angles(self, gt: np.array, proj: np.array):\n",
    "        centers = []\n",
    "        indexes = []\n",
    "        angles = []\n",
    "        for _ in range(1000):\n",
    "            idcs = np.random.choice(len(gt), 2)\n",
    "            indexes.append(idcs)\n",
    "\n",
    "            gt1, proj1 = gt[idcs[0]], proj[idcs[0]]\n",
    "            gt2, proj2 = gt[idcs[1]], proj[idcs[1]]\n",
    "\n",
    "            c = self._get_center_of_rotation(gt1, proj1, gt2, proj2)\n",
    "            centers.append(c)\n",
    "            \n",
    "        mean_c = np.array([np.median([elm[0] for elm in centers]), np.median([elm[1] for elm in centers])])\n",
    "\n",
    "        for i in range(1000):\n",
    "            idcs = indexes[i]\n",
    "\n",
    "            gt1, proj1 = gt[idcs[0]], proj[idcs[0]]\n",
    "            gt2, proj2 = gt[idcs[1]], proj[idcs[1]]\n",
    "\n",
    "            try:\n",
    "                angle = self._get_rotation(gt1, proj1, gt2, proj2, mean_c)\n",
    "            except Exception as ex:\n",
    "                continue\n",
    "\n",
    "            angles.append(angle)\n",
    "\n",
    "        return centers, angles            \n",
    "            \n",
    "    \n",
    "    def _get_intersect(self, a1, a2, b1, b2):\n",
    "        \"\"\" \n",
    "        Returns the point of intersection of the lines passing through a2,a1 and b2,b1.\n",
    "        a1: [x, y] a point on the first line\n",
    "        a2: [x, y] another point on the first line\n",
    "        b1: [x, y] a point on the second line\n",
    "        b2: [x, y] another point on the second line\n",
    "        \"\"\"\n",
    "        s = np.vstack([a1,a2,b1,b2])        # s for stacked\n",
    "        h = np.hstack((s, np.ones((4, 1)))) # h for homogeneous\n",
    "        l1 = np.cross(h[0], h[1])           # get first line\n",
    "        l2 = np.cross(h[2], h[3])           # get second line\n",
    "        x, y, z = np.cross(l1, l2)          # point of intersection\n",
    "        if z == 0:                          # lines are parallel\n",
    "            return (float('inf'), float('inf'))\n",
    "        return (x/z, y/z)\n",
    "    \n",
    "    def _get_norm_of_disp(self, gt, proj):\n",
    "        vec = (proj - gt)\n",
    "        return (-vec[1], vec[0])\n",
    "    \n",
    "    def _get_center_of_rotation(self, gt1, proj1, gt2, proj2):\n",
    "        n1, n2 = self._get_norm_of_disp(gt1, proj1), self._get_norm_of_disp(gt2, proj2)\n",
    "\n",
    "        first_center = (gt1 + proj1) / 2\n",
    "        second_center = (gt2 + proj2) / 2\n",
    "\n",
    "        c = self._get_intersect(\n",
    "            first_center,\n",
    "            first_center + n1,\n",
    "            second_center,\n",
    "            second_center + n2,\n",
    "        )\n",
    "\n",
    "\n",
    "        return c\n",
    "    \n",
    "    def _get_rotation(self, gt1, proj1, gt2, proj2, c):\n",
    "        cgt1 = gt1 - c\n",
    "        cproj1 = proj1 - c\n",
    "\n",
    "        cgt2 = gt2 - c\n",
    "        cproj2 = proj2 - c\n",
    "\n",
    "\n",
    "        res = Rotation.align_vectors(\n",
    "            a=np.array(\n",
    "                [[*cgt1, 0],\n",
    "                 [*cgt2, 0]]\n",
    "            ),\n",
    "            b=np.array(\n",
    "                [\n",
    "                    [*cproj1, 0],\n",
    "                    [*cproj2, 0]\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "\n",
    "        return res[0]\n",
    "\n",
    "ref = DisplacementRefinerSolver(verbose=False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88dbfd0b-76d2-47dd-a9bf-bbb78985b747",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/99 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'process_file' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m f\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnpy\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m pe, oe \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_file\u001b[49m(ref, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, conf, camera_dict, gt_dict)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(pe, oe)\n\u001b[1;32m      9\u001b[0m pose_errors\u001b[38;5;241m.\u001b[39mappend(pe)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'process_file' is not defined"
     ]
    }
   ],
   "source": [
    "orientation_errors, pose_errors = [], []\n",
    "for s in seq:\n",
    "    p = f\"{VSP}/seq{s}\"\n",
    "    for f in tqdm(os.listdir(p)):\n",
    "        if f.split(\".\")[1] != \"npy\":\n",
    "            continue\n",
    "        pe, oe = process_file(ref, f\"{p}/{f}\", conf, camera_dict, gt_dict)\n",
    "        print(pe, oe)\n",
    "        pose_errors.append(pe)\n",
    "        orientation_errors.append(oe)\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51e7e6b-1286-4999-99b1-1de520e95aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = ref(\n",
    "    np.array(pts2D),\n",
    "    np.array(pts3D),\n",
    "    camera\n",
    ")\n",
    "res, type(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9fa0aadf-c029-4928-8038-f931b2198c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UP2PSolverPipeline(SP):\n",
    "    \n",
    "    def __init__(self, num_models_to_eval: int = 100, verbose: bool = False):\n",
    "        self.solver = Up2P()\n",
    "        self.sampler = Sampler()\n",
    "        self.num_models_to_eval = num_models_to_eval\n",
    "        self.verbose = verbose\n",
    "    \n",
    "    def __call__(self, pts2D, pts3D, camera_dict):\n",
    "        \n",
    "        w, h = camera_dict[\"width\"], camera_dict[\"height\"]\n",
    "        params = camera_dict[\"params\"]\n",
    "        f, cx, cy, _ = params\n",
    "        \n",
    "        pts2D = np.concatenate([pts2D, np.ones(pts2D.shape[0])[:, np.newaxis]], axis=1)\n",
    "        pts2D[:, 0] -= cx\n",
    "        pts2D[:, 1] -= cy\n",
    "        pts2D[:2] /= f\n",
    "        pts2D /= np.linalg.norm(pts2D)\n",
    "        \n",
    "        solution, sol_err = None, float(\"+inf\")\n",
    "        \n",
    "        iterator = range(self.num_models_to_eval)\n",
    "        \n",
    "        for i in (tqdm(iterator) if self.verbose else iterator):\n",
    "            try:\n",
    "                # +1 for evaluation in here\n",
    "                pts2d, idcs = self.sampler(pts2D, self.solver.get_sample_size() + 1)\n",
    "                pts3d = pts3D[idcs]\n",
    "\n",
    "                solv_res = self.solver(pts2d[:pts2d.shape[0] - 1], pts3d[:pts3d.shape[0] - 1])\n",
    "                best_sol, err = None, float(\"+inf\")\n",
    "                for sol in solv_res:\n",
    "                    R, t = sol\n",
    "                    R, t = R.detach().cpu().numpy(), t.detach().cpu().numpy()\n",
    "                    translated = R.T @ (pts3d[pts3d.shape[0] - 1] - t)\n",
    "                    translated[:2] /= translated[2]\n",
    "                    translated[:2] *= f\n",
    "                    translated[0] += cx\n",
    "                    translated[1] += cy\n",
    "                    if np.linalg.norm(translated - pts2d[pts2d.shape[0] - 1]) < err:\n",
    "                        err = np.linalg.norm(translated - pts2D[i])\n",
    "                        best_sol = sol\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "            if err < sol_err:\n",
    "                sol_err = err\n",
    "                solution = best_sol \n",
    "\n",
    "        pose = poselib.CameraPose()\n",
    "        pose.q = matrix_to_quaternion(solution[0])\n",
    "        pose.t = solution[1]\n",
    "        \n",
    "        return pose\n",
    "        \n",
    "solv_pipe = UP2PSolverPipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9a4a451-7a08-4cb5-972c-0f4ef2d763d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([q: 0.499404        0 0.866369        0, t:  12.0103 -13.8728 -0.64799],\n",
       " poselib.CameraPose)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = solv_pipe(\n",
    "    np.array(pts2D),\n",
    "    np.array(pts3D),\n",
    "    camera\n",
    ")\n",
    "res, type(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5247103-2b96-4c94-bfea-7064c25d7ad4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[q:  0.770395 -0.620412  0.145098 -0.022967, t:   12.4091   4.84072 -0.453523]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pose = p3pwrapper(\n",
    "    np.array(pts2D),\n",
    "    np.array(pts3D),\n",
    "    camera\n",
    ")\n",
    "pose.t = - pose.R.T @ pose.t\n",
    "pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "78988031-6139-4f07-8ae7-a44b4b1f47ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(executor: SP, path: str, conf, camera_dict, gts):\n",
    "    data = np.load(path)\n",
    "    pts2D = list(data[:, :2])\n",
    "    pts3D = list(data[:, 2:])\n",
    "    pp = \"/\".join(path.split(\"/\")[-2:])\n",
    "    pp = pp.replace(\"_matches\", \"\")\n",
    "    pp = pp.replace(\".npy\", \".png\")\n",
    "    camera_dict = camera_dict[pp]\n",
    "    gt = gts[pp]\n",
    "    c, r = gt[:3], gt[3:]\n",
    "\n",
    "    pose = executor(np.array(pts2D), np.array(pts3D), camera_dict)\n",
    "\n",
    "    pose.t = - pose.R.T @ pose.t          \n",
    "\n",
    "    gt_pose = poselib.CameraPose()\n",
    "    gt_pose.q = r / np.linalg.norm(r)\n",
    "\n",
    "    rot_error = np.arccos((np.trace(np.matmul(gt_pose.R.transpose(), pose.R)) - 1.0) / 2.0) * 180.0 / np.pi\n",
    "\n",
    "    if SHOW_SINGLE:\n",
    "        print(np.trace(np.matmul(gt_pose.R.transpose(), pose.R)))\n",
    "        print(\" Position error: \" + str(np.linalg.norm(c - pose.t)) + \" orientation error: \" + str(rot_error))\n",
    "    if np.isnan(rot_error):\n",
    "        return 1000000.0, 180.0\n",
    "    else:\n",
    "        return np.linalg.norm(c - pose.t), rot_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23ecb0a8-f54e-41c2-9972-e3eb0bb2d259",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_camera_dict(path: str, args):\n",
    "    with open(path) as file:\n",
    "        data = file.readlines()\n",
    "\n",
    "    camera_dict = {}\n",
    "    for _, line in enumerate(data):\n",
    "        # image width, image height, focal length, x of pp, y of pp, radial distortion factor \n",
    "        path, cam_type, w, h, f, x, y, rd = line.split()\n",
    "        scaling_factor = 320 / max(np.float32(w), np.float32(h))\n",
    "  \n",
    "        # camera = {'model': 'SIMPLE_PINHOLE', 'width': 1200, 'height': 800, 'params': [960, 600, 400]}\n",
    "        camera_dict[path] = {\n",
    "          'model': cam_type,\n",
    "          'width': int(np.float32(w) * scaling_factor),\n",
    "          'height': int(np.float32(h) * scaling_factor),\n",
    "          'params': list(map(float, [np.float32(f) * scaling_factor,\n",
    "                                 np.float32(x) * scaling_factor,\n",
    "                                 np.float32(y) * scaling_factor,\n",
    "                                 np.float32(rd)])),\n",
    "        }\n",
    "  \n",
    "    return camera_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "32718520-eed5-4863-b903-72f540a70216",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_gts(path: str):\n",
    "    # ImageFile, Camera Position [X Y Z W P Q R]\n",
    "\n",
    "    with open(path) as file:\n",
    "        data = file.readlines()\n",
    "\n",
    "    gts = {}\n",
    "    for _, line in enumerate(data):\n",
    "        try:\n",
    "          # seq13/frame00158.png 25.317314 -0.228082 54.493720 0.374564 0.002123 0.915022 -0.149782\n",
    "          path, x, y, z, w, p, q, r = line.split()\n",
    "          rest = [x, y, z, w, p, q, r]\n",
    "          rest = list(map(float, rest))\n",
    "        except Exception as ex:\n",
    "          # print(ex)\n",
    "          continue\n",
    "        gts[path] = rest\n",
    "\n",
    "    return gts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a7ccff08-7bad-4ea0-9545-0e084f2f8ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_dict = prepare_camera_dict(\n",
    "    \"dataset/StMarysChurch_matches/st_marys_church_list_queries_with_intrinsics_simple_radial_sorted.txt\",\n",
    "    conf\n",
    ")\n",
    "\n",
    "gt_dict = prepare_gts(\n",
    "    \"dataset/StMarysChurch_matches/dataset_test.txt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ef86a24f-de8f-4ee5-a488-81adb5010163",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [00:00<00:00, 212.67it/s]\n",
      "100%|██████████| 83/83 [00:00<00:00, 151.50it/s]\n",
      "100%|██████████| 351/351 [00:02<00:00, 118.18it/s]\n"
     ]
    }
   ],
   "source": [
    "orientation_errors, pose_errors = [], []\n",
    "for s in seq:\n",
    "    p = f\"{VSP}/seq{s}\"\n",
    "    for f in tqdm(os.listdir(p)):\n",
    "        if f.split(\".\")[1] != \"npy\":\n",
    "            continue\n",
    "        pe, oe = process_file(p3pwrapper, f\"{p}/{f}\", conf, camera_dict, gt_dict)\n",
    "        pose_errors.append(pe)\n",
    "        orientation_errors.append(oe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2b84dc38-935e-4c45-aeda-20787d5df81b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Couldn't localize 0 out of 530 images\n",
      " Median position error: 0.086, median orientation errors: 0.29\n",
      " Percentage of poses within the median: 41.132075471698116 % \n"
     ]
    }
   ],
   "source": [
    "pos_errors = pose_errors\n",
    "orient_errors = orientation_errors\n",
    "print(\" Couldn't localize \" + str(orientation_errors.count(180.0)) + \" out of \" + str(len(orientation_errors)) + \" images\") \n",
    "print(\" Median position error: \" +  str(round(statistics.median(pos_errors),3)) + \", median orientation errors: \" + str(round(statistics.median(orient_errors),2)))\n",
    "\n",
    "med_pos = statistics.median(pos_errors)\n",
    "med_orient = statistics.median(orient_errors)\n",
    "counter = 0\n",
    "for i in range(0, len(pose_errors)):\n",
    "    if pose_errors[i] <= med_pos and orientation_errors[i] <= med_orient:\n",
    "        counter += 1\n",
    "print(\" Percentage of poses within the median: \" + str(100.0 * float(counter) / float(len(pose_errors))) + \" % \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3283ef61-c62e-4b85-8437-558c5861c2f1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [00:09<00:00, 10.06it/s]\n",
      "100%|██████████| 83/83 [00:08<00:00,  9.87it/s]\n",
      "100%|██████████| 351/351 [00:30<00:00, 11.44it/s]\n"
     ]
    }
   ],
   "source": [
    "orientation_errors, pose_errors = [], []\n",
    "for s in seq:\n",
    "    p = f\"{VSP}/seq{s}\"\n",
    "    for f in tqdm(os.listdir(p)):\n",
    "        if f.split(\".\")[1] != \"npy\":\n",
    "            continue\n",
    "        pe, oe = process_file(solv_pipe, f\"{p}/{f}\", conf, camera_dict, gt_dict)\n",
    "        pose_errors.append(pe)\n",
    "        orientation_errors.append(oe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c27f9d12-dab9-42d3-9807-0333df328093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Couldn't localize 0 out of 530 images\n",
      " Median position error: 30.255, median orientation errors: 97.2\n",
      " Percentage of poses within the median: 24.71698113207547 % \n"
     ]
    }
   ],
   "source": [
    "pos_errors = pose_errors\n",
    "orient_errors = orientation_errors\n",
    "print(\" Couldn't localize \" + str(orientation_errors.count(180.0)) + \" out of \" + str(len(orientation_errors)) + \" images\") \n",
    "print(\" Median position error: \" +  str(round(statistics.median(pos_errors),3)) + \", median orientation errors: \" + str(round(statistics.median(orient_errors),2)))\n",
    "\n",
    "med_pos = statistics.median(pos_errors)\n",
    "med_orient = statistics.median(orient_errors)\n",
    "counter = 0\n",
    "for i in range(0, len(pose_errors)):\n",
    "    if pose_errors[i] <= med_pos and orientation_errors[i] <= med_orient:\n",
    "        counter += 1\n",
    "print(\" Percentage of poses within the median: \" + str(100.0 * float(counter) / float(len(pose_errors))) + \" % \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4ad2919d-9768-4c0c-8fbf-e5518e692df6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/99 [00:00<?, ?it/s]<ipython-input-8-cc40826060c0>:181: UserWarning: Optimal rotation is not uniquely or poorly defined for the given sets of vectors.\n",
      "  res = Rotation.align_vectors(\n",
      "100%|██████████| 99/99 [01:23<00:00,  1.19it/s]\n",
      "100%|██████████| 83/83 [01:33<00:00,  1.13s/it]\n"
     ]
    }
   ],
   "source": [
    "orientation_errors, pose_errors = [], []\n",
    "for s in seq[:-1]:\n",
    "    p = f\"{VSP}/seq{s}\"\n",
    "    for f in tqdm(os.listdir(p)):\n",
    "        if f.split(\".\")[1] != \"npy\":\n",
    "            continue\n",
    "        try:\n",
    "            pe, oe = process_file(ref, f\"{p}/{f}\", conf, camera_dict, gt_dict)\n",
    "            pose_errors.append(pe)\n",
    "            orientation_errors.append(oe)\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "185a3729-d50c-4908-843b-509c57aa5f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Couldn't localize 0 out of 170 images\n",
      " Median position error: 27.301, median orientation errors: 123.95\n",
      " Percentage of poses within the median: 18.823529411764707 % \n"
     ]
    }
   ],
   "source": [
    "pos_errors = pose_errors\n",
    "orient_errors = orientation_errors\n",
    "print(\" Couldn't localize \" + str(orientation_errors.count(180.0)) + \" out of \" + str(len(orientation_errors)) + \" images\") \n",
    "print(\" Median position error: \" +  str(round(statistics.median(pos_errors),3)) + \", median orientation errors: \" + str(round(statistics.median(orient_errors),2)))\n",
    "\n",
    "med_pos = statistics.median(pos_errors)\n",
    "med_orient = statistics.median(orient_errors)\n",
    "counter = 0\n",
    "for i in range(0, len(pose_errors)):\n",
    "    if pose_errors[i] <= med_pos and orientation_errors[i] <= med_orient:\n",
    "        counter += 1\n",
    "print(\" Percentage of poses within the median: \" + str(100.0 * float(counter) / float(len(pose_errors))) + \" % \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1eea41b-d2ab-4a14-9479-65a49c014f5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
