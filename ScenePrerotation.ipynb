{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d3776f8-fe0a-42d6-97d9-7b4875ff32e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.colors import Normalize\n",
    "\n",
    "from tqdm import tqdm\n",
    "from solver import Up2P\n",
    "from utils.rotation_utils import get_upward_with_dev, get_rt_mtx, validate_sol\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eebe7650-4355-4a89-96e7-778e2f18d286",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    max_depth: float = 10.\n",
    "    img_width: int = 640\n",
    "    img_height: int = 640\n",
    "    focal_length: int = 3 * (img_width * 0.5) / np.tan(60.0 * np.pi / 180.0);\n",
    "    min_depth: float = 1.\n",
    "    max_depth: float = 1.1\n",
    "    inliers_ratio: float = 1.\n",
    "    outlier_dist: float = 30.\n",
    "    \n",
    "    # [TODO][IMPORTNAT]: not properly tested, be aware of using for\n",
    "    # some experiments\n",
    "    pixel_noise: float = 0.\n",
    "    \n",
    "conf = Config()\n",
    "dtype = torch.float64\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d96120e-9a52-4783-835b-941482f7538b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_correspondence(x: torch.tensor, conf: Config):\n",
    "    x = to_camera_coords(x, conf)\n",
    "    x *= random.uniform(conf.min_depth, conf.max_depth)\n",
    "    \n",
    "    assert x.shape == (3,)    \n",
    "    return x\n",
    "\n",
    "def transform_correspondence(X: torch.tensor, R: torch.tensor, t: torch.tensor):\n",
    "    return R @ X + t\n",
    "\n",
    "def to_homogeneous(x):\n",
    "    return torch.cat([x, torch.ones(1)])\n",
    "\n",
    "def to_camera_coords(x: torch.tensor, conf: Config = conf):\n",
    "    x = to_homogeneous(x)\n",
    "    \n",
    "    x[0] -= conf.img_width // 2\n",
    "    x[1] -= conf.img_height // 2\n",
    "    x[:2] /= conf.focal_length\n",
    "    x /= x.norm()\n",
    "    \n",
    "    return x\n",
    "\n",
    "def reproject(X, R, t, conf: Config = conf):\n",
    "    translated = R.T @ (X - t)\n",
    "    translated[:2] /= translated[2]\n",
    "    translated[:2] *= conf.focal_length\n",
    "    translated[0] += conf.img_width // 2\n",
    "    translated[1] += conf.img_height // 2\n",
    "    \n",
    "    return translated[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "650db9a4-72d0-4d6e-a13b-1068502ba7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.rotation_utils import get_random_upward\n",
    "\n",
    "def get_random_image_point(conf: Config):\n",
    "    x = random.uniform(0, conf.img_width)\n",
    "    y = random.uniform(0, conf.img_height)\n",
    "    x = torch.tensor([x, y], dtype=torch.float64)    \n",
    "    return x\n",
    "\n",
    "\n",
    "def generate_example(R, t, conf: Config = conf):\n",
    "    x1, x2 = get_random_image_point(conf), get_random_image_point(conf)\n",
    "    X1, X2 = generate_correspondence(x1.clone(), conf),\\\n",
    "             generate_correspondence(x2.clone(), conf)\n",
    "    X1, X2 = transform_correspondence(X1, R, t), transform_correspondence(X2, R, t)\n",
    "    \n",
    "    # [TODO][IMPORTNAT]: not properly tested, be aware of using for\n",
    "    # some experiments\n",
    "    if conf.pixel_noise != 0:\n",
    "        x1noise = np.random.normal(0, conf.pixel_noise, 2)\n",
    "        x2noise = np.random.normal(0, conf.pixel_noise, 2)\n",
    "        \n",
    "        if torch.all(x1[0] + x1noise > 0) and torch.all(x1[1] + x1noise < conf.img_width):\n",
    "            x1 += x1noise\n",
    "            assert x1[0] > 0 and x1[1] < conf.img_width, f\"{x1}\"\n",
    "            \n",
    "        if torch.all(x2[0] + x2noise > 0) and torch.all(x2[1] + x2noise < conf.img_height):\n",
    "            x2 += x2noise\n",
    "            assert x2[0] > 0 and x2[1] < conf.img_height, f\"{x2}\"\n",
    "        \n",
    "        assert x1[0] > 0 and x1[1] < conf.img_width, f\"{x1}\"\n",
    "        assert x2[0] > 0 and x2[1] < conf.img_height, f\"{x2}\"\n",
    "        \n",
    "    return x1, x2, X1, X2 \n",
    "        \n",
    "def generate_examples(num_of_examples: int,\n",
    "                      dev: Tuple[float, float] = (0., 0.), conf: Config = conf):\n",
    "    num_of_examples = num_of_examples // 2\n",
    "    \n",
    "    num_inliers = num_of_examples * conf.inliers_ratio\n",
    "    num_outliers = num_of_examples - num_inliers\n",
    "    \n",
    "    if num_of_examples == 0:\n",
    "        num_of_examples, num_inliers, num_outliers = 1, 1, 0\n",
    "    \n",
    "    R, rand_angle = get_random_upward(*dev)\n",
    "    t = torch.rand(3, )\n",
    "        \n",
    "    # [TODO] [IMPORTANT]: under such generation we cannot get model where one of the points is an inlier\n",
    "    xs, Xs, inliers = [], [], []\n",
    "    for i in range(num_of_examples):\n",
    "        x1, x2, X1, X2 = generate_example(R, t)\n",
    "        Xs.append((X1, X2))\n",
    "        \n",
    "        if i < num_inliers:\n",
    "            xs.append((x1, x2))\n",
    "            inliers.append(True)\n",
    "        else:\n",
    "            xs.append((generate_outlier(x1, conf), generate_outlier(x2, conf)))\n",
    "            inliers.append(False)\n",
    "            \n",
    "    return xs, Xs, inliers, R, t, rand_angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2230ac5f-cb94-4a5c-bb15-8545a1f0559c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:02<00:00, 381.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res=995, skipped=0, Success rate: 0.995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([601.,  50.,  48.,  43.,  31.,  38.,  37.,  36.,  36.,  80.]),\n",
       " array([8.78076395e-10, 2.82839091e-01, 5.65678180e-01, 8.48517270e-01,\n",
       "        1.13135636e+00, 1.41419545e+00, 1.69703454e+00, 1.97987363e+00,\n",
       "        2.26271272e+00, 2.54555181e+00, 2.82839090e+00]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "PREROTATE = True\n",
    "res = 0\n",
    "skipped = 0\n",
    "\n",
    "rot_errors = []\n",
    "for _ in tqdm(range(1000)):\n",
    "    solver = Up2P()\n",
    "\n",
    "    x=0\n",
    "    z=40\n",
    "    prerot = get_rt_mtx(roll=x, pitch=0, yaw=z, device=device, dtype=torch.float64)\n",
    "\n",
    "    xs, Xs, _, Rg, tg, rand_angle = generate_examples(2, dev=(x, z))\n",
    "    xs, Xs = list(xs[0]), list(Xs[0])\n",
    "    txs, tXs = xs[1][0], Xs[1][0]\n",
    "\n",
    "    xsc = torch.zeros((2, 3))\n",
    "    xsc[0] = to_camera_coords(xs[0], conf)\n",
    "    xsc[1] = to_camera_coords(xs[1], conf)\n",
    "\n",
    "    if PREROTATE:\n",
    "        Xs = [prerot.T @ X for X in Xs]\n",
    "\n",
    "    err, Re, te = None, None, None\n",
    "    for R, t in solver(xsc, torch.stack(Xs)):   \n",
    "        # t = -R.T @ t # done by the solve itself\n",
    "        rp = R.T @ (tXs - t)\n",
    "        rp[:2] /= rp[2]\n",
    "        rp[:2] *= conf.focal_length\n",
    "        rp[0] += conf.img_width // 2\n",
    "        rp[1] += conf.img_height // 2\n",
    "        rp = rp[:2]\n",
    "    \n",
    "        # rp = reproject(tXs, R, t, conf)\n",
    "        cerr = (txs - rp).norm()\n",
    "        if err is None or cerr < err:\n",
    "            err = cerr\n",
    "            Re, te = R, t\n",
    "\n",
    "    if Re is None:\n",
    "        # print(cerr)\n",
    "        skipped += 1\n",
    "    else:\n",
    "        res += torch.allclose(reproject(Xs[0], Re, te, conf), xs[0]) and torch.allclose(reproject(Xs[1], Re, te, conf), xs[1])\n",
    "        true_R = prerot @ Re\n",
    "        rot_errors.append((Rg - true_R).norm())\n",
    "        \n",
    "print(f\"{res=}, {skipped=}, Success rate: {res / (1000 - skipped)}\")\n",
    "plt.hist(rot_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7a0b366-d7a3-4e85-9bf7-6a0a2101814c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:02<00:00, 368.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res=996, skipped=0, Success rate: 0.996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([ 68.,  60.,  68.,  66.,  75.,  73.,  82.,  98., 135., 275.]),\n",
       " array([1.98273174, 2.06639987, 2.15006801, 2.23373615, 2.31740428,\n",
       "        2.40107242, 2.48474055, 2.56840869, 2.65207682, 2.73574496,\n",
       "        2.81941309]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "res = 0\n",
    "skipped = 0\n",
    "rot_errors = []\n",
    "\n",
    "for _ in tqdm(range(1000)):\n",
    "\n",
    "    solver = Up2P()\n",
    "\n",
    "    xs, Xs, _, Rg, tg, rand_angle = generate_examples(2, dev=(0, 0))\n",
    "    xs, Xs = list(xs[0]), list(Xs[0])\n",
    "    txs, tXs = xs[1][0], Xs[1][0]\n",
    "\n",
    "    xsc = torch.zeros((2, 3))\n",
    "    xsc[0] = to_camera_coords(xs[0], conf)\n",
    "    xsc[1] = to_camera_coords(xs[1], conf)\n",
    "\n",
    "    err, Re, te = None, None, None\n",
    "    for R, t in solver(xsc, torch.stack(Xs)):    \n",
    "        rp = reproject(tXs, R, t, conf)\n",
    "        cerr = (txs - rp).norm()\n",
    "        \n",
    "        if err is None or cerr < err:\n",
    "            err = cerr\n",
    "            Re, te = R, t\n",
    "\n",
    "    if Re is None:\n",
    "        skipped += 1\n",
    "    else:\n",
    "        res += torch.allclose(reproject(Xs[0], Re, te, conf), xs[0]) and torch.allclose(reproject(Xs[1], Re, te, conf), xs[1])\n",
    "        rot_errors.append((Rg - true_R).norm())\n",
    "    \n",
    "print(f\"{res=}, {skipped=}, Success rate: {res / (1000 - skipped)}\")\n",
    "plt.hist(rot_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4296e496-7c80-4041-8540-3dc9019989d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfcc6ef-fa6d-4dc9-9360-e6010bc6750b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
