{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d3776f8-fe0a-42d6-97d9-7b4875ff32e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.colors import Normalize\n",
    "\n",
    "from tqdm import tqdm\n",
    "from solver import Up2P\n",
    "from utils.rotation_utils import get_upward_with_dev, get_rt_mtx, validate_sol\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eebe7650-4355-4a89-96e7-778e2f18d286",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    max_depth: float = 10.\n",
    "    img_width: int = 640\n",
    "    img_height: int = 640\n",
    "    focal_length: int = 3 * (img_width * 0.5) / np.tan(60.0 * np.pi / 180.0);\n",
    "    min_depth: float = 1.\n",
    "    max_depth: float = 1.1\n",
    "    inliers_ratio: float = 1.\n",
    "    outlier_dist: float = 30.\n",
    "    \n",
    "    # [TODO][IMPORTNAT]: not properly tested, be aware of using for\n",
    "    # some experiments\n",
    "    pixel_noise: float = 0.\n",
    "    \n",
    "conf = Config()\n",
    "dtype = torch.float64\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d96120e-9a52-4783-835b-941482f7538b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_correspondence(x: torch.tensor, conf: Config):\n",
    "    x = to_camera_coords(x, conf)\n",
    "    x *= random.uniform(conf.min_depth, conf.max_depth)\n",
    "    \n",
    "    assert x.shape == (3,)    \n",
    "    return x\n",
    "\n",
    "def transform_correspondence(X: torch.tensor, R: torch.tensor, t: torch.tensor):\n",
    "    return R @ X + t\n",
    "\n",
    "def to_homogeneous(x):\n",
    "    return torch.cat([x, torch.ones(1)])\n",
    "\n",
    "def to_camera_coords(x: torch.tensor, conf: Config = conf):\n",
    "    x = to_homogeneous(x)\n",
    "    \n",
    "    x[0] -= conf.img_width // 2\n",
    "    x[1] -= conf.img_height // 2\n",
    "    x[:2] /= conf.focal_length\n",
    "    x /= x.norm()\n",
    "    \n",
    "    return x\n",
    "\n",
    "def reproject(X, R, t, conf: Config = conf):\n",
    "    translated = R.T @ (X - t)\n",
    "    translated[:2] /= translated[2]\n",
    "    translated[:2] *= conf.focal_length\n",
    "    translated[0] += conf.img_width // 2\n",
    "    translated[1] += conf.img_height // 2\n",
    "    \n",
    "    return translated[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "650db9a4-72d0-4d6e-a13b-1068502ba7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.rotation_utils import get_random_upward\n",
    "\n",
    "def get_random_image_point(conf: Config):\n",
    "    x = random.uniform(0, conf.img_width)\n",
    "    y = random.uniform(0, conf.img_height)\n",
    "    x = torch.tensor([x, y], dtype=torch.float64)    \n",
    "    return x\n",
    "\n",
    "\n",
    "def generate_example(R, t, conf: Config = conf):\n",
    "    x1, x2 = get_random_image_point(conf), get_random_image_point(conf)\n",
    "    X1, X2 = generate_correspondence(x1.clone(), conf),\\\n",
    "             generate_correspondence(x2.clone(), conf)\n",
    "    X1, X2 = transform_correspondence(X1, R, t), transform_correspondence(X2, R, t)\n",
    "    \n",
    "    # [TODO][IMPORTNAT]: not properly tested, be aware of using for\n",
    "    # some experiments\n",
    "    if conf.pixel_noise != 0:\n",
    "        x1noise = np.random.normal(0, conf.pixel_noise, 2)\n",
    "        x2noise = np.random.normal(0, conf.pixel_noise, 2)\n",
    "        \n",
    "        if torch.all(x1[0] + x1noise > 0) and torch.all(x1[1] + x1noise < conf.img_width):\n",
    "            x1 += x1noise\n",
    "            assert x1[0] > 0 and x1[1] < conf.img_width, f\"{x1}\"\n",
    "            \n",
    "        if torch.all(x2[0] + x2noise > 0) and torch.all(x2[1] + x2noise < conf.img_height):\n",
    "            x2 += x2noise\n",
    "            assert x2[0] > 0 and x2[1] < conf.img_height, f\"{x2}\"\n",
    "        \n",
    "        assert x1[0] > 0 and x1[1] < conf.img_width, f\"{x1}\"\n",
    "        assert x2[0] > 0 and x2[1] < conf.img_height, f\"{x2}\"\n",
    "        \n",
    "    return x1, x2, X1, X2 \n",
    "        \n",
    "def generate_examples(num_of_examples: int,\n",
    "                      dev: Tuple[float, float] = (0., 0.), conf: Config = conf):\n",
    "    num_of_examples = num_of_examples // 2\n",
    "    \n",
    "    num_inliers = num_of_examples * conf.inliers_ratio\n",
    "    num_outliers = num_of_examples - num_inliers\n",
    "    \n",
    "    if num_of_examples == 0:\n",
    "        num_of_examples, num_inliers, num_outliers = 1, 1, 0\n",
    "    \n",
    "    R, rand_angle = get_random_upward(*dev)\n",
    "    t = torch.rand(3, )\n",
    "        \n",
    "    # [TODO] [IMPORTANT]: under such generation we cannot get model where one of the points is an inlier\n",
    "    xs, Xs, inliers = [], [], []\n",
    "    for i in range(num_of_examples):\n",
    "        x1, x2, X1, X2 = generate_example(R, t)\n",
    "        Xs.append((X1, X2))\n",
    "        \n",
    "        if i < num_inliers:\n",
    "            xs.append((x1, x2))\n",
    "            inliers.append(True)\n",
    "        else:\n",
    "            xs.append((generate_outlier(x1, conf), generate_outlier(x2, conf)))\n",
    "            inliers.append(False)\n",
    "            \n",
    "    return xs, Xs, inliers, R, t, rand_angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2230ac5f-cb94-4a5c-bb15-8545a1f0559c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:01<00:00, 530.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res=996, skipped=0, Success rate: 0.996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([443.,  78.,  80.,  77.,  48.,  56.,  56.,  34.,  34.,  94.]),\n",
       " array([2.21320276e-09, 2.82837720e-01, 5.65675437e-01, 8.48513155e-01,\n",
       "        1.13135087e+00, 1.41418859e+00, 1.69702631e+00, 1.97986403e+00,\n",
       "        2.26270174e+00, 2.54553946e+00, 2.82837718e+00]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "PREROTATE = True\n",
    "res = 0\n",
    "skipped = 0\n",
    "\n",
    "rot_errors = []\n",
    "for _ in tqdm(range(1000)):\n",
    "    solver = Up2P()\n",
    "\n",
    "    x=0\n",
    "    z=40\n",
    "    prerot = get_rt_mtx(roll=x, pitch=0, yaw=z, device=device, dtype=torch.float64)\n",
    "\n",
    "    xs, Xs, _, Rg, tg, rand_angle = generate_examples(2, dev=(x, z))\n",
    "    xs, Xs = list(xs[0]), list(Xs[0])\n",
    "    txs, tXs = xs[1][0], Xs[1][0]\n",
    "\n",
    "    xsc = torch.zeros((2, 3))\n",
    "    xsc[0] = to_camera_coords(xs[0], conf)\n",
    "    xsc[1] = to_camera_coords(xs[1], conf)\n",
    "\n",
    "    if PREROTATE:\n",
    "        Xs = [prerot.T @ X for X in Xs]\n",
    "\n",
    "    err, Re, te = None, None, None\n",
    "    for R, t in solver(xsc, torch.stack(Xs)):   \n",
    "        # t = -R.T @ t # done by the solve itself\n",
    "        rp = R @ (tXs - t)\n",
    "        rp[:2] /= rp[2]\n",
    "        rp[:2] *= conf.focal_length\n",
    "        rp[0] += conf.img_width // 2\n",
    "        rp[1] += conf.img_height // 2\n",
    "        rp = rp[:2]\n",
    "    \n",
    "        # rp = reproject(tXs, R, t, conf)\n",
    "        cerr = (txs - rp).norm()\n",
    "        if err is None or cerr < err:\n",
    "            err = cerr\n",
    "            Re, te = R, t\n",
    "\n",
    "    if Re is None:\n",
    "        # print(cerr)\n",
    "        skipped += 1\n",
    "    else:\n",
    "        res += torch.allclose(reproject(Xs[0], Re, te, conf), xs[0]) and torch.allclose(reproject(Xs[1], Re, te, conf), xs[1])\n",
    "        true_R = prerot @ Re\n",
    "        rot_errors.append((Rg - true_R).norm())\n",
    "        \n",
    "print(f\"{res=}, {skipped=}, Success rate: {res / (1000 - skipped)}\")\n",
    "plt.hist(rot_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7a0b366-d7a3-4e85-9bf7-6a0a2101814c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:02<00:00, 368.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res=996, skipped=0, Success rate: 0.996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([ 68.,  60.,  68.,  66.,  75.,  73.,  82.,  98., 135., 275.]),\n",
       " array([1.98273174, 2.06639987, 2.15006801, 2.23373615, 2.31740428,\n",
       "        2.40107242, 2.48474055, 2.56840869, 2.65207682, 2.73574496,\n",
       "        2.81941309]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "res = 0\n",
    "skipped = 0\n",
    "rot_errors = []\n",
    "\n",
    "for _ in tqdm(range(1000)):\n",
    "\n",
    "    solver = Up2P()\n",
    "\n",
    "    xs, Xs, _, Rg, tg, rand_angle = generate_examples(2, dev=(0, 0))\n",
    "    xs, Xs = list(xs[0]), list(Xs[0])\n",
    "    txs, tXs = xs[1][0], Xs[1][0]\n",
    "\n",
    "    xsc = torch.zeros((2, 3))\n",
    "    xsc[0] = to_camera_coords(xs[0], conf)\n",
    "    xsc[1] = to_camera_coords(xs[1], conf)\n",
    "\n",
    "    err, Re, te = None, None, None\n",
    "    for R, t in solver(xsc, torch.stack(Xs)):    \n",
    "        rp = reproject(tXs, R, t, conf)\n",
    "        cerr = (txs - rp).norm()\n",
    "        \n",
    "        if err is None or cerr < err:\n",
    "            err = cerr\n",
    "            Re, te = R, t\n",
    "\n",
    "    if Re is None:\n",
    "        skipped += 1\n",
    "    else:\n",
    "        res += torch.allclose(reproject(Xs[0], Re, te, conf), xs[0]) and torch.allclose(reproject(Xs[1], Re, te, conf), xs[1])\n",
    "        rot_errors.append((Rg - true_R).norm())\n",
    "    \n",
    "print(f\"{res=}, {skipped=}, Success rate: {res / (1000 - skipped)}\")\n",
    "plt.hist(rot_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4296e496-7c80-4041-8540-3dc9019989d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfcc6ef-fa6d-4dc9-9360-e6010bc6750b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
